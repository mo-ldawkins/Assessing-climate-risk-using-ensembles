"""
Code to apply risk assessment framework, GAM and generate plots for the paper A

You first need to save the conda folder and the 'climada_netcdf' folder to a relevant place
"""

import warnings
from netCDF4 import Dataset
import sys
import numpy as np
import glob

home_dir = '/data/users/ldawkins/UKCR/CodeToShare/' # change to location of the Sup Material folder
data_dir = home_dir+'Data/'

sys.path.append(home_dir + 'climada_netcdf/climada_python/')
warnings.filterwarnings('ignore')

#import climada functions
from climada.hazard import Hazard
from climada.entity import Exposures
from climada.entity import ImpactFunc, ImpactFuncSet
from climada.entity import Entity
from climada.engine import Impact


# Define the vulnerability/impact function
def impf_func(p1, p2, haz_type, int_unit, _id=1):

    def imp_arc1(hum, p1, p2):
        return 1-1/(1+(p1/hum)**(p2))

    imp_fun = ImpactFunc()
    imp_fun.haz_type = haz_type
    imp_fun.id = _id
    imp_fun.intensity_unit =  int_unit
    imp_fun.intensity = np.linspace(0, 100, num=100)
    imp_fun.mdd = np.repeat(1, len(imp_fun.intensity))
    imp_fun.paa = np.array([imp_arc1(hum, p1, p2) for hum in imp_fun.intensity])
    imp_fun.check()
    impf_set = ImpactFuncSet()
    impf_set.append(imp_fun)
    return impf_set

# Input
# 1. data source: Obs (hist + change factor), DePreSys (hist + change factor?), UKCP_raw, UKCP_BC,
# 2. warming level (current, 2deg, 4deg)
# 3. SSP
# 4. Vuln function params

# Function to carry out CLIMADA implementation
def Apply_CLIMADA_risk_assessment(data_source, warming_level, ssp, ssp_year, ens_mem, vfn_p1=54.5, vfn_p2=-4.1,
                                  variable='humidex', haz_type='Heatstress', int_unit='degC', exp_unit='Days',
                                  save_all_imp=False):
    # find the required hazard (humidex) data file
    if ens_mem == 'nan':
        if warming_level == 'current':
            netcdf_file_path = glob.glob(
                data_dir + data_source + '/*humidex*1998*')
        else:
            netcdf_file_path = glob.glob(
                data_dir + data_source + '/*humidex*'+warming_level+'*')
    else:
        if warming_level == 'current':
            netcdf_file_path = glob.glob(
                    data_dir + data_source + '/*'+ens_mem+'_*humidex*1998*')
        else:
            netcdf_file_path = glob.glob(
                data_dir + data_source + '/*'+ens_mem+'_*humidex*'+warming_level+'*')
    # load in hazard (humidex) data
    netcdf_file = Dataset(netcdf_file_path[0])
    nyears_data = round(netcdf_file.dimensions['time'].size/360) # the risk calculation needs to know the number of years

    nyears =  (360*nyears_data)/(360-102-8-25)   # 360 days per year, 102 weekend days, 8 bank holidays, 25 days AL

    if nyears_data >= 15: # don't want to calculate risk for periods not representative of the warming level
        hazard_args = {'intensity_var': variable,
                       'event_id': np.arange(len(netcdf_file.variables['time'])),
                       'frequency': np.full(len(netcdf_file.variables['time']), 1/nyears),
                       'haz_type': haz_type,
                       'description': 'Hazard data',
                       'replace_value': np.nan,
                       'fraction_value': 1.0}
        hazard = Hazard.from_netcdf(netcdf_file_path[0], **hazard_args)
        hazard.check() # this line is required by CLIMADA to assign all necessary variables

        # Exposure
        # load in exposure file (here the no. of jobs in physical outdoor occupations)
        exp_file_name = data_dir + '/UKSSPs/Employment_SSP'+ssp+'_12km_Physical.nc'
        exp = Exposures.from_netcdf(exp_file_name, 'employment', int(ssp_year)) # load in picking out SSP year of interest (e.g. 2020 for current, 2041 for 2 degree etc.)
        exp.value_unit = exp_unit
        exp.set_geometry_points()
        exp.check()

        # define the impact/vulnerability function
        imp_set = impf_func(p1=vfn_p1, p2=vfn_p2,  haz_type=haz_type, int_unit=int_unit, _id=1)

        # Entity - bring everything together
        entity = Entity()
        entity.exposures = exp
        entity.impact_funcs = imp_set

        # Impact - calculate impact and risk
        impact = Impact()
        impact.calc(entity.exposures, entity.impact_funcs, hazard, save_mat='True')

        # Save out EAI (expected annual impact)

        # latitude, longitude
        shape = [len(netcdf_file.variables['projection_y_coordinate']), len(netcdf_file.variables['projection_x_coordinate'])]
        annual_impact_meta = {"data_source": "Annual Impact Data generated by climada"}

        if ens_mem == np.nan:
            eai_netcdf = data_dir + data_source+'/expected_annual_impact_data_'+data_source+'_WL'+warming_level+'_SSP'+ssp+'_vp1='+str(vfn_p1)+'_vp2='+str(vfn_p2)+'.nc'
        else:
            eai_netcdf = data_dir + data_source+'/expected_annual_impact_data_'+data_source+'_ens'+ens_mem+'_WL'+warming_level+'_SSP'+ssp+'_vp1='+str(vfn_p1)+'_vp2='+str(vfn_p2)+'.nc'

        impact.eai_to_netcdf(eai_netcdf, shape, annual_impact_meta)

        # Save out full Impact - all days
        if save_all_imp == True:
            impact_meta = {"data_source": "Impact Data generated by climada"}

            if ens_mem == np.nan:
                imp_netcdf = data_dir + data_source+'/all_impact_data_' + data_source + '_WL' + warming_level + '_SSP' + ssp +'_vp1='+str(vfn_p1)+'_vp2='+str(vfn_p2)+'.nc'
            else:
                imp_netcdf = data_dir + data_source+'/all_impact_data_' + data_source + '_ens' + ens_mem + '_WL' + warming_level + '_SSP' + ssp +'_vp1='+str(vfn_p1)+'_vp2='+str(vfn_p2)+'.nc'

            impact.imp_to_netcdf(imp_netcdf, shape, netcdf_file_path, impact_meta)
    else:
        print('Not enough years of data in time slice')

############################ -----------------------------------


# Run the functions to assess risk for Obs and UKCP18 bias corrected data
data_source = 'Obs'
warming_level = 'current'
ssp = '2'
ssp_year = '2020'
ens_mem = 'nan'

# Obs
Apply_CLIMADA_risk_assessment(data_source, warming_level, ssp, ssp_year, ens_mem)

# Do the same for:
# data_source = 'UKCP_BC'
# lopping over
# warming_level = ['current','2deg','4deg']
# ens_mem = ['01', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '15']

# This takes some memory so may be best not to run on local PC
